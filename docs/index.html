<!DOCTYPE HTML>

<html xmlns="http://www.w3.org/1999/html" xmlns="http://www.w3.org/1999/html">
	<head>
		<title>FewNLU</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<span class="logo"><img src="images/logo.svg" alt="" /></span>
						<h1><strong>FewNLU: Benchmarking Natural Language Understanding</strong></h1>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#intro" class="active">Introduction</a></li>
							<li><a href="https://super.gluebenchmark.com">Paper</a></li>
							<li><a href="#toolkit">Toolkit</a></li>
							<li><a href="#leaderboard">Leaderboard</a></li>
							<li><a href="https://super.gluebenchmark.com">Download</a></li>

						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Introduction -->
							<section id="intro" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2><strong>Introduction to FewNLU</strong></h2>
										</header>
										<p> Few-shot natural language understanding has attracted much recent attention.
											However, prior methods have been evaluated under a diverse set of
											protocols, which hinders fair comparison and measuring progress of the
											field.
											It is quested for a converged evaluation protocol as well as a general toolkit for few-shot NLU.
											FewNLU addresses this issue from the following aspects.
											<ul><ul><ul><li> FewNLU introduces an evaluation framework of few-shot NLU,
											and uses comprehensive experiments to justify the choices of data split
											construction and hyper-parameter search space formulation.
											The evaluation framework can be viewed as correction, improvement, and
											unification of previous evaluation protocols.
											</li>
											<li> Under this evaluation framework, a number of recently-proposed
											state-of-the-art methods are re-evaluated.
											Through these experiments, we benchmark the performance of prior methods
											individually as well as the best performance with a combined approach. </li>
											<li> We open-source a toolkit FewNLU to facilitate future
											research based on our evaluation framework.
											FewNLU also contains the implementation of a number of few-shot methods
												along with data processing utilities.</li></ul></ul></ul>

										Please refer to our <strong><a href="https://super.gluebenchmark.com">Paper
									</a></strong> for
										more details.
										We also release a new version of FewGLUE dataset for <strong><a
											href="https://super.gluebenchmark.com">Download
									</a></strong>, which has been experimented in our paper.
										</p>
									</div>
								</div>
							</section>

						<!-- First Section -->
						<!--
							<section id="first" class="main special">
								<header class="major">
									<h2>Data Download</h2>
								</header>
								<ul class="features">
									<li>
										<span class="icon solid major style1 fa-code"></span>
										<h3>Recommended Few-shot Setting</h3>
										<p align="left">The benchmark dataset supports our recommended legal & effective few-shot learning by providing an additional small-size development set of 32 examples.</p>
									</li>
									<li>
										<span class="icon major style3 fa-copy"></span>
										<h3>Diverse & Complicated NLU Tasks</h3>
										<p align="left">The tasks are complicated sentence-pair or sentence-triple tasks that demand advanced understanding capabilities. Besides, the tasks are diverse, ranging from question answering, textual entailment, co-reference resolution, causal reasoning to word sense disambiguation.</p>
									</li>
									<li>
										<span class="icon major style5 fa-gem"></span>
										<h3>Support Integrating Other Learning Paradigms</h3>
										<p align="left">The benchmark dataset also supports research that integrates other learning paradigms (such as semi-supervised learning) with few-shot learning by providing additional unlabeled datasets.</p>
									</li>
								</ul>
								<footer class="major">
									<ul class="actions special">
										<li><a href="https://cloud.tsinghua.edu.cn/f/6e9cd075d9024dc3b6db/?dl=1" class="button">Download Data</a></li>
									</ul>
								</footer>
							</section>
						-->
						<!-- Second Section -->
							<section id="toolkit" class="main special">
								<header class="major">
									<h2><strong>FewNLU Toolkit</strong></h2>
								</header>
								<p align="left">
									We open-source FewNLU, an integrated toolkit designed for few-shot natural language understanding.
									It contains implementation of several state-of-the-art methods, data processing
									utilities, a standardized few-shot training framework, and most importantly, the proposed evaluation framework.
									FewNLU also allows customizing new tasks and methods,  and performing training and
									evaluation over them.
									The goal of FewNLU is to facilitate benchmarking few-shot NLU methods and
									to facilitate future research in related field.
									Key features and capabilities of FewNLU include:
								</p>
								<ul class="features">
									<li>
										<span class="icon solid major style1 fa-code"></span>
										<h3><strong>An Evaluation Framework with Recommended
											Data-split Strategy</strong></h3>
										<p align="left">
											We propose an evaluation framework for few-shot NLU.
											The newly-formulated framework consists of a repeated
											procedure -- selecting a hyperparameter, selecting a data split,
											training and evaluating the model.
										</p>
									</li>
									<li>
										<span class="icon major style3 fa-copy"></span>
										<h3><strong>A Collection of State-of-the-Art Methods for Few-Shot NLU</strong></h3>
										<p align="left">
											The FewNLU toolkit contains a number of state-of-the-art few-shot
											methods. We take a further step to re-evaluate them under the
											newly-proposed evaluation framework and report the results in
											<strong><a href="#leaderboard">Leaderboard</a></strong>.
										</p>
									</li>
									<li>
										<span class="icon major style5 fa-gem"></span>
										<h3><strong>Easy-to-Use Customization of Tasks and Methods</strong></h3>
										<p align="left">
											FewNLU allows customizing new tasks or methods with easy-to-use interfaces.
											Customization enables NLU to easily scale to a diverse range of future works.
										</p>
									</li>
								</ul>
								<footer class="major">
									<ul class="actions special">
										<li><a href="https://github.com/THUDM/FewNLU/README.md" class="button">Get
											Started with FewNLU Toolkit
										</a></li>
									</ul>
								</footer>
							</section>

						<!-- Get Started -->
							<section id="leaderboard" class="main special">
								<header class="major">
									<h2>Leaderboard</h2>
								</header>
								<p align="left">
									<font size="3" color="red">
										<i> Report your results:
										If you have new results experimented with FewNLU, please send emails to
										<a href = "mailto:zyanan93@gmail.com">zyanan93@gmail.com</a> or
										<a href = "mailto:zhouj18@mails.tsinghua.edu.cn">zhouj18@mails.tsinghua.edu.cn</a>
										attached with the link to your paper or reproducible source codes! Thank you!
										</i>
									</font>
								</p>
									<table>
										<tbody>
										<tr>
											<th> <strong> Methods </strong> </th>
											<th> <strong> URL </strong> </th>
											<th> <strong> BoolQ(Acc) </strong> </th>
											<th> <strong> RTE(Acc) </strong> </th>
											<th> <strong> WiC(Acc) </strong> </th>
											<th> <strong> CB(Acc/F1) </strong> </th>
											<th> <strong> MultiRC(F1a/EM)</strong> </th>
											<th> <strong> WSC(Acc)</strong> </th>
											<th> <strong> COPA(Acc)</strong> </th>
											<th> <strong> Avg. </strong> </th>
										</tr>

										<tr>
											<th>&#127775; Combination<sup>1234</sup> </th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 84.00 </th>
											<th> 83.70 </th>
											<th> 69.60 </th>
											<th> 94.60/92.90 </th>
											<th> 81.00/46.00 </th>
											<th> 88.20 </th>
											<th> 93.80 </th>
											<th> 84.99 </th>
										</tr>


										<tr>
											<th> CLS<sup>1</sup> </th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 59.49 </th>
											<th> 49.55 </th>
											<th> 54.08 </th>
											<th> 68.30/60.10 </th>
											<th> 75.42/34.23 </th>
											<th> 60.82 </th>
											<th> 85.25 </th>
											<th> 61.17 </th>
										</tr>

										<tr>
											<th> PET<sup>1</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 82.67 </th>
											<th> 79.42 </th>
											<th> 67.20 </th>
											<th> 91.96/88.63 </th>
											<th> 78.18/42.79 </th>
											<th> 80.53 </th>
											<th> 89.00 </th>
											<th> 78.51 </th>
										</tr>

										<tr>
											<th> ADAPET<sup>1</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 81.28 </th>
											<th> 82.58 </th>
											<th> 66.50 </th>
											<th> 89.73/86.63 </th>
											<th> 77.88/43.05 </th>
											<th> 83.41 </th>
											<th> 88.75 </th>
											<th> 78.74 </th>
										</tr>

										<tr>
											<th> P-Tuning<sup>1</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 82.25 </th>
											<th> 82.22 </th>
											<th> 66.22 </th>
											<th> 94.20/91.76 </th>
											<th> 78.45/43.78 </th>
											<th> 84.62 </th>
											<th> 86.50 </th>
											<th> 79.41 </th>
										</tr>
										<tr>
											<th> PET+MLM<sup>12</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 82.80 </th>
											<th> 83.30 </th>
											<th> 58.23 </th>
											<th> 90.18/87.18 </th>
											<th> 77.05/40.63 </th>
											<th> 78.37 </th>
											<th> 85.75 </th>
											<th> 76.57 </th>
										</tr>

										<tr>
											<th> iPET (single)<sup>123</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 81.27 </th>
											<th> 81.11 </th>
											<th> 64.75 </th>
											<th> 89.88/87.70 </th>
											<th> 79.99/45.23 </th>
											<th> 86.06 </th>
											<th> 90.83 </th>
											<th> 79.35 </th>
										</tr>

										<tr>
											<th> noisy_student(single)<sup>123</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 81.60 </th>
											<th> 81.95 </th>
											<th> 65.97 </th>
											<th> 91.67/89.17 </th>
											<th> 79.85/45.10 </th>
											<th> 84.78 </th>
											<th> 90.67 </th>
											<th> 79.69 </th>
										</tr>

										<tr>
											<th> iPET (cross)<sup>123</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 83.45 </th>
											<th> 83.12 </th>
											<th> 69.63 </th>
											<th> 91.52/90.72 </th>
											<th> 79.92/44.96 </th>
											<th> 88.22 </th>
											<th> 93.75 </th>
											<th> 81.68 </th>
										</tr>

										<tr>
											<th> noisy_student(cross)<sup>123</sup></th>
											<th> <a href="https://github.com/THUDM/FewNLU/">(code)</a> </th>
											<th> 82.28 </th>
											<th> 79.87 </th>
											<th> 67.20 </th>
											<th> 89.73/88.49 </th>
											<th> 80.51/45.12 </th>
											<th> 84.13 </th>
											<th> 90.00 </th>
											<th> 79.34 </th>
										</tr>
									</table>
								<p align="left" style="line-height:100%">
									<font size="3">
										Notes:</br>
										1. The method uses DeBERTa-xxlarge-v2 as base pretrained model.</br>
										2. Unlabeled data are used.</br>
										3. The ensemble technique is used.</br>
										4. Combination of diverse methods such as prompt-based
										finetuning, loss regularization and self-training data augmentation etc.
										Refer to <strong><a href="https://super.gluebenchmark.com">Paper
									</a></strong> for details.
									</font>
								</p>
								</tbody>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Design: <a href="https://github.com/THUDM">THUDM</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>